# -*- coding: utf-8 -*-
"""An MLOps Pipeline using Apache Airflow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cVL6q0-3w7VPw-vzv7DkKQi0fsWVyvT1

# **Data Prep**
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
from sklearn.preprocessing import MinMaxScaler

df = pd.read_csv("screentime_analysis.csv")
print(df)

print(df.isnull().sum())
print(df.duplicated().sum())

#Convert Datetime and extract features
df = pd.read_csv("screentime_analysis.csv")
df['Date']=pd.to_datetime(df['Date'])
df['DayOfWeek'] = df['Date'].dt.dayofweek
df['Month']=df['Date'].dt.month

df = pd.get_dummies(df, columns=['App'], drop_first=True)

# scale numerical features using MinMaxScaler
scaler=MinMaxScaler()
df[['Notifications', 'Times Opened']] = scaler.fit_transform(df[['Notifications', 'Times Opened']])

# feature engineering
df['Previous_Day_Usage'] = df['Usage (minutes)'].shift(1)
df['Notifications_x_TimesOpened'] = df['Notifications'] * df['Times Opened']

# save the preprocessed data to a file
df.to_csv('preprocessed_screentime_analysis.csv', index=False)

"""The process scales numerical columns, such as **Notifications** and **Times Opened**, using MinMaxScaler to ensure uniformity. Feature engineering creates lagged **(Previous_Day_Usage)** and interaction **(Notifications_x_TimesOpened)** features to enhance predictive power.

# **Train The Model**
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# split data into features and target variable
X = df.drop(columns=['Usage (minutes)', 'Date'])
y = df['Usage (minutes)']

# train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# train the model
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# evaluate the model
predictions = model.predict(X_test)
mae = mean_absolute_error(y_test, predictions)
print(f'Mean Absolute Error: {mae}')

"""The **Mean Absolute Error (MAE)** metric quantifies the average difference between the predicted and actual values to assess performance.

--> On average, the model’s predicted screentime differs from the actual screentime by approximately 15.4 minutes --> the model performs reasonably well **><** still room for improvement in reducing this error to make predictions more precise.

# **Automating Preprocessing with a Pipeline using Apache Airflow**
"""

pip install apache-airflow

from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from datetime import datetime

# define the data preprocessing function
def preprocess_data():
    file_path = 'screentime_analysis.csv'
    df = pd.read_csv(file_path)

    df['Date'] = pd.to_datetime(df['Date'])
    df['DayOfWeek'] = df['Date'].dt.dayofweek
    df['Month'] = df['Date'].dt.month

    df = df.drop(columns=['Date'])

    df = pd.get_dummies(df, columns=['App'], drop_first=True)

    scaler = MinMaxScaler()
    df[['Notifications', 'Times Opened']] = scaler.fit_transform(df[['Notifications', 'Times Opened']])

    preprocessed_path = 'preprocessed_screentime_analysis.csv'
    df.to_csv(preprocessed_path, index=False)
    print(f"Preprocessed data saved to {preprocessed_path}")

# define the DAG
dag = DAG(
    dag_id='data_preprocessing',
    schedule='@daily', # Changed schedule_interval to schedule
    start_date=datetime(2025, 1, 1),
    catchup=False,
)

# define the task
preprocess_task = PythonOperator(
    task_id='preprocess',
    python_callable=preprocess_data,
    dag=dag,
)

"""# **Testing and Running Pipeline**"""

!airflow db init

get_ipython().system('airflow webserver --port 8080')

!airflow scheduler